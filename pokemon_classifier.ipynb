{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqBh9M51kPVi"
      },
      "source": [
        "## Trabalho Final de Inteligência Artificial (INF 420)\n",
        "\n",
        "### Tema: Pokémon Classifier\n",
        "\n",
        "##### > Alunos: Erick Lima Figueiredo e Sávio mendes Miranda\n",
        "##### > Matrículas: 98898, 98886 | Professor: Júlio Cesar Soares dos Reis\n",
        "\n",
        "---\n",
        "\n",
        "#### **Objetivo do Trabalho:** Produzir uma Rede Neural Convolucional para Classificação multiclasse de Pokémon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCaoWwI3kteH"
      },
      "source": [
        "### Bibliotecas utilizadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "95J0Qo9kj1KC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYb4sAABsJDa"
      },
      "source": [
        "### Configurando Comportamento da GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "U4P-waXDsS8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de GPUs disponíveis:  1\n",
            "As GPUs foram configuradas para alocar memória à medida que for necessário.\n"
          ]
        }
      ],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "print('Número de GPUs disponíveis: ', len(gpus))\n",
        "\n",
        "for gpu in gpus:\n",
        "  tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "print('As GPUs foram configuradas para alocar memória à medida que for necessário.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d_eODE-hzpf"
      },
      "source": [
        "### Obtenção e Divisão dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mA5b8uzAqtZf"
      },
      "outputs": [],
      "source": [
        "ROOT_PATH = r'D:\\Documents\\test'\n",
        "TRAIN_PERCENTAGE = .7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "images_train = []\n",
        "images_test = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "folders = [os.path.join(ROOT_PATH, i) for i in os.listdir(ROOT_PATH) if os.path.isdir(os.path.join(ROOT_PATH, i))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hqNEnpN4q0cg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Existem 101 images alocadas para treino e 44 imagens alocadas para teste.\n"
          ]
        }
      ],
      "source": [
        "for folder in folders:\n",
        "    files = os.listdir(folder)\n",
        "\n",
        "    total_files = len(files)\n",
        "    num_train = math.floor(total_files * .7)\n",
        "\n",
        "    random.shuffle(files)\n",
        "\n",
        "    images_train = images_train + \\\n",
        "        [os.path.join(folder, file) for file in files[:num_train]]\n",
        "    images_test = images_test + \\\n",
        "        [os.path.join(folder, file) for file in files[num_train:]]\n",
        "\n",
        "\n",
        "TRAIN_SIZE = len(images_train)\n",
        "TEST_SIZE = len(images_test)\n",
        "\n",
        "print(f'Existem {TRAIN_SIZE} images alocadas para treino e {TEST_SIZE} imagens alocadas para teste.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Mover a Localização dos Dados Empregados (Dispensável se executado diretamente)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_FOLDER = os.path.join(ROOT_PATH, 'train')\n",
        "TEST_FOLDER = os.path.join(ROOT_PATH, 'test')\n",
        "\n",
        "if not os.path.isdir(TRAIN_FOLDER):\n",
        "    os.mkdir(TRAIN_FOLDER)\n",
        "    print(f'Diretório \"train\" criado em {ROOT_PATH}.')\n",
        "\n",
        "\n",
        "if not os.path.isdir(TEST_FOLDER):\n",
        "    os.mkdir(TEST_FOLDER)\n",
        "    print(f'Diretório \"test\" criado em {ROOT_PATH}.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dispensável se está executando tudo de uma vez\n",
        "for img in images_train:\n",
        "    shutil.copy(img, TRAIN_FOLDER)\n",
        "\n",
        "\n",
        "for img in images_test:\n",
        "    shutil.copy(img, TEST_FOLDER)\n",
        "\n",
        "print('Images copiadas!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Aplicação de Hot Encoding nas Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hot encode completo:\n",
            "{'8 Bits': [1, 0, 0, 0], 'Artes minimalistas em geral': [0, 1, 0, 0], 'test': [0, 0, 1, 0], 'train': [0, 0, 0, 1]}\n"
          ]
        }
      ],
      "source": [
        "AMOUNT_CLASSES = len(folders)\n",
        "\n",
        "classes_reference = {}\n",
        "\n",
        "for i, path in enumerate(folders):\n",
        "    name = path.split(os.sep)[-1]\n",
        "    classes_reference[name] = [0]*AMOUNT_CLASSES\n",
        "    classes_reference[name][i] = 1\n",
        "\n",
        "print(f'Hot encode completo:\\n{classes_reference}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definição do Augmentador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip('horizontal_and_vertical'),\n",
        "    tf.keras.layers.RandomRotation(.2),\n",
        "    tf.keras.layers.RandomZoom(.2),\n",
        "    tf.keras.layers.RandomContrast(.3)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FABI7D4h8yH"
      },
      "source": [
        "### Definição dos Datasets para Execução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_SHAPE = (64, 64, 3) # Vamos trabalhar com imagens pequenas por questões de limitação de hardware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_train_data():\n",
        "    for i in range(TRAIN_SIZE):\n",
        "        img = cv2.imread(images_train[i])\n",
        "        img = cv2.resize(img, IMG_SHAPE) # Redimensionamento da imagem e definição de canais RGB\n",
        "        img /= 255.0 # Normalização\n",
        "        \n",
        "        img = data_augmentation(img) # Augmentação da imagem\n",
        "        \n",
        "        label = images_train[i].split(os.sep)[-2]\n",
        "        label = classes_reference[label] # Captura do label encodado\n",
        "\n",
        "        yield img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_test_data():\n",
        "    for i in range(TEST_SIZE):\n",
        "        img = cv2.imread(images_test[i])\n",
        "        img = cv2.resize(img, IMG_SHAPE) # Redimensionamento da imagem e definição de canais RGB\n",
        "        img /= 255.0 # Normalização\n",
        "        \n",
        "        img = data_augmentation(img) # Augmentação da imagem\n",
        "        \n",
        "        label = images_train[i].split(os.sep)[-2]\n",
        "        label = classes_reference[label] # Captura do label encodado\n",
        "\n",
        "        yield img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaNRqYKWtNpB"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    generator=generate_train_data, output_types=(tf.float64, tf.int32)).batch(BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWQdj3ZXti3Q"
      },
      "outputs": [],
      "source": [
        "test_dataset = tf.data.Dataset.from_generator(\n",
        "    generator=generate_test_data, output_types=(tf.float64, tf.int32)).batch(BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3TSMlwuiE7N"
      },
      "source": [
        "### Definição dos Modelos de Rede Neural para Classificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nosso modelo vai trabalhar com as seguintes **Funções de Ativação**:\n",
        "- Rectified Linear Unit (ReLU): Retorna o valor máximo entre 0 e o tensor de entrada;\n",
        "- Softmax: Mais indicada para trabalhar com modelos de classificação multiclasse (em comparação com a sigmoid), basicamente converte um vetor de valor para uma distribuição de probabilidades."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utilizaremos um modelo sequencial composto pelos seguintes layers:\n",
        "- Conv2D (Input Layer): Estabelece um núcleo de convolução alterando as dimensões do input para uma matriz 2D.\n",
        "- MaxPooling2D: Reduz a entrada no quesito altura e largura, tomando o valor máximo sobre uma janela (deslocada em passos, varrendo a imagem) de entrada para cada canal da entrada.\n",
        "- Flatten: Achata as dimensões do input.\n",
        "- Dense (Output Layer): Dense implementa a operação: $$output = activation(dot(input, kernel) + bias)$$ onde a ativação é a função de ativação no sentido do elemento passado como argumento de ativação, kernel é uma matriz de pesos criada pela camada, e bias é um vetor de bias criado pela camada (somente aplicável se o uso_bias for Verdadeiro)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TbQYTOvfrcru"
      },
      "outputs": [],
      "source": [
        "def create_model(using_v2=False):\n",
        "    if using_v2:\n",
        "        return '' # Criar um outro layout de modelo aqui\n",
        "    \n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(64, (6, 6), padding='same', input_shape=IMG_SHAPE, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (4, 4), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(AMOUNT_CLASSES, activation='softmax')\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_model() # instanciamos nosso modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explicação:** Para compilar o modelo utilizaremos o otimizador Adam, que é uma abordagem mais recente e tida como mais eficiente que a abordagem de Gradiente Descendente (Gradient Descent), utilizaremos como função de avaliação de perda a `Categorical Crossentropy` que é aplicada quando existem duas ou mais classes envolvidas, é importante salientar que essa função espera labels no formato de codificação _one hot_ como já providenciamos nos códigos acima, além disso vamos usar a acurácia (proximidade entre o valor obtido experimentalmente e o valor verdadeiro) como métrica de avaliação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bFbTqbJiuIiG"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),  # Usado ao invés do Gradiente descendente Estocástico\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mais detalhes podem ser obtidos na documentação da biblioteca [Keras](https://keras.io/api/) utilizado como o backend do TensorFlow neste trabalho."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Visão Geral do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RTOS6TnEvsIT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 64, 64, 64)        4864      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 32, 32, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 16, 16, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32768)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 131076    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 209,796\n",
            "Trainable params: 209,796\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKu9jP3KiPln"
      },
      "source": [
        "### Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xDouBdsfrdPG"
      },
      "outputs": [],
      "source": [
        "# Aplicaremos a callback abaixo para evitar que nosso modelo entre em overfitting\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss',mode='min',verbose=1,patience=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWkajSvbumRX"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset, epochs=NUM_EPOCHS, callbacks=[early_stop])\n",
        "print('Treinamento completo =)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weights = model.get_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ti8AFMviTF1"
      },
      "source": [
        "### Avaliação e Análise de Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5GMC-zyrdsj"
      },
      "outputs": [],
      "source": [
        "result = model.evaluate(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASgOooLAiYZi"
      },
      "source": [
        "### Armazenamento do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZp9XwtxvQK6"
      },
      "outputs": [],
      "source": [
        "SAVE_DIR = r''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohwM1dz2u0RM"
      },
      "outputs": [],
      "source": [
        "model.save(SAVE_DIR+os.sep+'model.h5', save_format='h5')\n",
        "print('Modelo salvo com sucesso!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Trabalho Final - INF 420 - Inteligência Artificial",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('uacs')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "6373fee0a68d35a0d82e9ee8e26bee416c1ea42635abfee08bec30cc192adbf8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
